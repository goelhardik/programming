Quora challenge Labeler.

Files:
bayes_classifier.py
- written in python3.4.
- reads input from files and outputs to another file

checker.py
- scoring script
- invoke as "./checker.py labeler_sample.ans labeler_sample.out"

common_eng_words.txt
- list of common english words
- used by bayes_classifier.py

copy_bayes.py
- written in python3.4
- reads from stdin and outputs to stdout

copy_bayes2.py
- written in python2
- reads from stdin and outputs to stdout

labeler_sample.in
- input file with training set and queries

labeler_sample.ans
- file with correct answers

labeler_sample.out
- answers generated by bayes_classifier.py

***************************************************************************

When a user adds a question to Quora, we automatically suggest topics which 
might be relevant to the question. For example, a question about Dijkstra's 
algorithm would probably fit well under the topics "Algorithms" and "Graph 
Theory".

We have a pretty good machine learning system in place for generating these 
topics, but it could always be better. Your goal in this task is to design a 
question topic labeler.

The input data consists of a training dataset of TT questions and an evaluation 
dataset of EE  questions. Your labeler should suggest 10 topics for each 
question in the evaluation set, ordered by relevance.

Input Format
The first line consists of two space-separated integers TT and 
E(1≤T≤20000,1≤E≤1000)E(1≤T≤20000,1≤E≤1000) .

The next 2T2T  lines provide the training dataset. Each question in the training 
dataset is described by two lines:

One integer N(1≤N≤25)N(1≤N≤25) , followed by NN positive integers (below 250) 
representing the topic IDs of the question in no particular order. On average, 
there are approximately 3 topics per question in the dataset.
One string (between 1 and 500 printable ASCII characters), the question text. 
The average question text length is 70 characters.

The next EE lines provide the evaluation dataset. Each question in the 
evaluation dataset is described by one line (between 1 and 500 ASCII 
characters), the question text.

Output Format
There are TT lines in total. The ii-th line contains 10 space-separated 
integers, each representing the topic id of a suggestion for the ii-th question 
in the evaluation dataset. To maximize your score, topic suggestions for a 
question should be ordered in descending order of relevance.

Sample Input
6 4
3 1 2 4
What is the meaning of life?
7 1 2 5 8 9 11 15
What is Quora?
2 14 178
What are the best Google calendar hacks?
3 117 93 125
Why does government of China not value the freedom of speech?
2 65 164
What is the best piece of design ever?
5 197 183 29 170 143
What was the last conversation you had with your father?
Are programming contests fun?
What is machine learning?
How do you code in C++?
Is it possible to sort in linear time?


Note: a more comprehensive sample input (with the same training data made 
available during evaluation) is available here (input, correct topics). You can 
use this script to score your output for the sample dataset.

Sample Output
1 2 5 3 7 9 11 10 14 15
2 9 29 3 117 197 1 183 178 15
15 197 170 143 8 5 1 7 2 14
1 8 14 164 125 15 2 65 164 3


Scoring
Your score for each question is determined as follows:

∑i=0910−i√⋅(guessi∈questionTopics)∑i=0min(|questionTopics|,10)−110−i√∑i=0910−i⋅(guessi∈questionTopics)∑i=0min(|questionTopics|,10)−110−i

Your raw score is the sum of each question score.

minScoreminScore = raw score for classifier that guesses 10 most frequent 
topics.

Your final score is 
200⋅yourRawScore−minScoreE−minScore200⋅yourRawScore−minScoreE−minScore.

Resource Limits
Your program is limited to 512 MB of memory and must run in 60 seconds or less.
